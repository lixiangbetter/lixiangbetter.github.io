<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="hadoop,">










<meta name="description" content="Hadoop笔记一.Hadoop1.hdfs写流程  客户端跟namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在 namenode返回是否可以上传 client请求第一个 block该传输到哪些datanode服务器上 namenode返回3个datanode服务器ABC client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline">
<meta name="keywords" content="hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop笔记">
<meta property="og:url" content="http://yoursite.com/2020/07/02/Hadoop笔记/index.html">
<meta property="og:site_name" content="Thinking">
<meta property="og:description" content="Hadoop笔记一.Hadoop1.hdfs写流程  客户端跟namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在 namenode返回是否可以上传 client请求第一个 block该传输到哪些datanode服务器上 namenode返回3个datanode服务器ABC client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408194104141.png">
<meta property="og:image" content="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408194104141.png">
<meta property="og:image" content="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408195459150.png">
<meta property="og:image" content="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408195710128.png">
<meta property="og:image" content="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408221056627.png">
<meta property="og:image" content="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTU3MzQ4Mi8yMDE5MDMvMTU3MzQ4Mi0yMDE5MDMwMTEzNTkzNzE1OS03ODYwNDI2MTgucG5n.jpeg">
<meta property="og:updated_time" content="2020-07-03T00:48:08.406Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop笔记">
<meta name="twitter:description" content="Hadoop笔记一.Hadoop1.hdfs写流程  客户端跟namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在 namenode返回是否可以上传 client请求第一个 block该传输到哪些datanode服务器上 namenode返回3个datanode服务器ABC client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline">
<meta name="twitter:image" content="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408194104141.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/07/02/Hadoop笔记/">





  <title>Hadoop笔记 | Thinking</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Thinking</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/02/Hadoop笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Thinking">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hadoop笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-07-02T11:22:17+08:00">
                2020-07-02
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/bigdata/" itemprop="url" rel="index">
                    <span itemprop="name">bigdata</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>次
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Hadoop笔记"><a href="#Hadoop笔记" class="headerlink" title="Hadoop笔记"></a>Hadoop笔记</h1><h1 id="一-Hadoop"><a href="#一-Hadoop" class="headerlink" title="一.Hadoop"></a>一.Hadoop</h1><h2 id="1-hdfs写流程"><a href="#1-hdfs写流程" class="headerlink" title="1.hdfs写流程"></a>1.hdfs写流程</h2><p><img src="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408194104141.png" alt></p>
<ol>
<li>客户端跟namenode通信请求上传文件，namenode检查目标文件是否已存在，父目录是否存在</li>
<li>namenode返回是否可以上传</li>
<li>client请求第一个 block该传输到哪些datanode服务器上</li>
<li>namenode返回3个datanode服务器ABC</li>
<li>client请求3台dn中的一台A上传数据（本质上是一个RPC调用，建立pipeline），A收到请求会继续调用B，然后B调用C，将真个pipeline建立完成，逐级返回客户端</li>
<li>client开始往A上传第一个block（先从磁盘读取数据放到一个本地内存缓存），以packet为单位，A收到一个packet就会传给B，B传给C；A每传一个packet会放入一个应答队列等待应答</li>
<li>当一个block传输完成之后，client再次请求namenode上传第二个block的服务器。</li>
</ol>
<h2 id="2-hdfs读流程"><a href="#2-hdfs读流程" class="headerlink" title="2.hdfs读流程"></a>2.hdfs读流程</h2><p><img src="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408194104141.png" alt></p>
<ol>
<li>client跟namenode通信查询元数据，找到文件块所在的datanode服务器</li>
<li>挑选一台datanode（就近原则，然后随机）服务器，请求建立socket流</li>
<li>datanode开始发送数据（从磁盘里面读取数据放入流，以packet为单位来做校验）</li>
<li>客户端以packet为单位接收，现在本地缓存，然后写入目标文件</li>
</ol>
<h2 id="3-hdfs的体系结构"><a href="#3-hdfs的体系结构" class="headerlink" title="3.hdfs的体系结构"></a>3.hdfs的体系结构</h2><p>hdfs有namenode、secondraynamenode、datanode组成。为n+1模式</p>
<ol>
<li>NameNode负责管理和记录整个文件系统的元数据</li>
<li>DataNode 负责管理用户的文件数据块，文件会按照固定的大小（blocksize）切成若干块后分布式存储在若干台datanode上，每一个文件块可以有多个副本，并存放在不同的datanode上，Datanode会定期向Namenode汇报自身所保存的文件block信息，而namenode则会负责保持文件的副本数量</li>
<li>HDFS的内部工作机制对客户端保持透明，客户端请求访问HDFS都是通过向namenode申请来进行</li>
<li>secondraynamenode负责合并日志</li>
</ol>
<h2 id="4-一个datanode-宕机-怎么一个流程恢复"><a href="#4-一个datanode-宕机-怎么一个流程恢复" class="headerlink" title="4.一个datanode 宕机,怎么一个流程恢复"></a>4.一个datanode 宕机,怎么一个流程恢复</h2><p>Datanode宕机了后，如果是短暂的宕机，可以事先写好脚本监控，将它启动起来。如果是长时间宕机了，那么datanode上的数据应该已经被备份到其他机器了，那这台datanode就是一台新的datanode了，删除他的所有数据文件和状态文件，重新启动。</p>
<h2 id="5-hadoop-的-namenode-宕机-怎么解决"><a href="#5-hadoop-的-namenode-宕机-怎么解决" class="headerlink" title="5.hadoop 的 namenode 宕机,怎么解决"></a>5.hadoop 的 namenode 宕机,怎么解决</h2><p>先分析宕机后的损失，宕机后直接导致client无法访问，内存中的元数据丢失，但是硬盘中的元数据应该还存在，如果只是节点挂了，重启即可，如果是机器挂了，重启机器后看节点是否能重启，不能重启就要找到原因修复了。但是最终的解决方案应该是在设计集群的初期就考虑到这个问题，做namenode的HA。</p>
<h2 id="6-namenode对元数据的管理"><a href="#6-namenode对元数据的管理" class="headerlink" title="6.namenode对元数据的管理"></a>6.namenode对元数据的管理</h2><p>namenode对数据的管理采用了三种存储形式：</p>
<ul>
<li>内存元数据(NameSystem)</li>
<li>磁盘元数据镜像文件(fsimage镜像)</li>
<li>数据操作日志文件（可通过日志运算出元数据）(edit日志文件)</li>
</ul>
<h2 id="7-元数据的checkpoint"><a href="#7-元数据的checkpoint" class="headerlink" title="7.元数据的checkpoint"></a>7.元数据的checkpoint</h2><p>每隔一段时间，会由secondary namenode将namenode上积累的所有edits和一个最新的fsimage下载到本地，并加载到内存进行merge（这个过程称为checkpoint）</p>
<p><img src="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408195459150.png" alt></p>
<p>namenode和secondary namenode的工作目录存储结构完全相同，所以，当namenode故障退出需要重新恢复时，可以从secondary namenode的工作目录中将fsimage拷贝到namenode的工作目录，以恢复namenode的元数据</p>
<h2 id="8-yarn资源调度流程"><a href="#8-yarn资源调度流程" class="headerlink" title="8.yarn资源调度流程"></a>8.yarn资源调度流程</h2><p><img src="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408195710128.png" alt></p>
<ol>
<li>用户向YARN 中提交应用程序， 其中包括ApplicationMaster 程序、启动ApplicationMaster 的命令、用户程序等。</li>
<li>ResourceManager 为该应用程序分配第一个Container， 并与对应的NodeManager 通信，要求它在这个Container 中启动应用程序的ApplicationMaster。</li>
<li>ApplicationMaster 首先向ResourceManager 注册， 这样用户可以直接通过ResourceManager 查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。</li>
<li>ApplicationMaster 采用轮询的方式通过RPC 协议向ResourceManager 申请和领取资源。</li>
<li>一旦ApplicationMaster 申请到资源后，便与对应的NodeManager 通信，要求它启动任务。</li>
<li>NodeManager 为任务设置好运行环境（包括环境变量、JAR 包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。</li>
<li>各个任务通过某个RPC 协议向ApplicationMaster 汇报自己的状态和进度，以让ApplicationMaster 随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC 向ApplicationMaster 查询应用程序的当前运行状态。</li>
<li>应用程序运行完成后，ApplicationMaster 向ResourceManager 注销并关闭自己。</li>
</ol>
<h2 id="9-hadoop中combiner和partition的作用"><a href="#9-hadoop中combiner和partition的作用" class="headerlink" title="9.hadoop中combiner和partition的作用"></a>9.hadoop中combiner和partition的作用</h2><ul>
<li>combiner是发生在map的最后一个阶段，父类就是Reducer，意义就是对每一个maptask的输出进行局部汇总，以减小网络传输量，缓解网络传输瓶颈，提高reducer的执行效率。</li>
<li>partition的主要作用将map阶段产生的所有kv对分配给不同的reducer task处理，可以将reduce阶段的处理负载进行分摊</li>
</ul>
<h2 id="10-用mapreduce怎么处理数据倾斜问题？"><a href="#10-用mapreduce怎么处理数据倾斜问题？" class="headerlink" title="10.用mapreduce怎么处理数据倾斜问题？"></a>10.用mapreduce怎么处理数据倾斜问题？</h2><p>数据倾斜：map /reduce程序执行时，reduce节点大部分执行完毕，但是有一个或者几个reduce节点运行很慢，导致整个程序的处理时间很长，这是因为某一个key的条数比其他key多很多（有时是百倍或者千倍之多），这条key所在的reduce节点所处理的数据量比其他节点就大很多，从而导致某几个节点迟迟运行不完，此称之为数据倾斜。</p>
<p>（1）局部聚合加全局聚合。</p>
<p>第一次在 map 阶段对那些导致了数据倾斜的 key 加上 1 到 n 的随机前缀，这样本来相</p>
<p>同的 key 也会被分到多个 Reducer 中进行局部聚合，数量就会大大降低。</p>
<p>第二次 mapreduce，去掉 key 的随机前缀，进行全局聚合。</p>
<p>思想：二次 mr，第一次将 key 随机散列到不同 reducer 进行处理达到负载均衡目的。第</p>
<p>二次再根据去掉 key 的随机前缀，按原 key 进行 reduce 处理。</p>
<p>这个方法进行两次 mapreduce，性能稍差。</p>
<p>（2）增加 Reducer，提升并行度</p>
<p>JobConf.setNumReduceTasks(int)</p>
<p>（3）实现自定义分区</p>
<p>根据数据分布情况，自定义散列函数，将 key 均匀分配到不同 Reducer</p>
<h2 id="11-shuffle-阶段-你怎么理解的"><a href="#11-shuffle-阶段-你怎么理解的" class="headerlink" title="11.shuffle 阶段,你怎么理解的"></a>11.shuffle 阶段,你怎么理解的</h2><p><img src="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/20200408221056627.png" alt>shuffle: 洗牌、发牌——（核心机制：缓存，数据分区，排序，Merge进行局部value的合并）；</p>
<p>具体来说：就是将maptask输出的处理结果数据，分发给reducetask，并在分发的过程中，对数据按key进行了分区和排序；</p>
<p>1）Map 方法之后 Reduce 方法之前这段处理过程叫 Shuffle</p>
<p>2）Map 方法之后，数据首先进入到分区方法，把数据标记好分区，然后把数据发送到 环形缓冲区；环形缓冲区默认大小 100m，环形缓冲区达到 80%时，进行溢写；溢写前对数 据进行排序，排序按照对 key 的索引进行字典顺序排序，排序的手段快排；溢写产生大量溢 写文件，需要对溢写文件进行归并排序；对溢写的文件也可以进行 Combiner 操作，前提是汇总操作，求平均值不行。最后将文件按照分区存储到磁盘，等待 Reduce 端拉取。</p>
<p>3）每个 Reduce 拉取 Map 端对应分区的数据。拉取数据后先存储到内存中，内存不够 了，再存储到磁盘。拉取完所有数据后，采用归并排序将内存和磁盘中的数据都进行排序。</p>
<p>在进入 Reduce 方法前，可以对数据进行分组操作。</p>
<h2 id="13-MapReduce优化经验"><a href="#13-MapReduce优化经验" class="headerlink" title="13.MapReduce优化经验"></a>13.MapReduce优化经验</h2><ol>
<li>设置合理的map和reduce的个数。合理设置blocksize</li>
<li>避免出现数据倾斜</li>
<li>combine函数</li>
<li>对数据进行压缩</li>
<li>小文件处理优化：事先合并成大文件，combineTextInputformat，在hdfs上用mapreduce将小文件合并SequenceFile大文件（key:文件名，value：文件内容）</li>
<li>参数优化</li>
</ol>
<h2 id="14-分别举例什么情况要使用-combiner，什么情况不使用？"><a href="#14-分别举例什么情况要使用-combiner，什么情况不使用？" class="headerlink" title="14.分别举例什么情况要使用 combiner，什么情况不使用？"></a>14.分别举例什么情况要使用 combiner，什么情况不使用？</h2><p>求平均数的时候就不需要用combiner，因为不会减少reduce执行数量。在其他的时候，可以依据情况，使用combiner，来减少map的输出数量，减少拷贝到reduce的文件，从而减轻reduce的压力，节省网络开销，提升执行效率</p>
<h2 id="15-MR运行流程解析"><a href="#15-MR运行流程解析" class="headerlink" title="15.MR运行流程解析"></a>15.MR运行流程解析</h2><ol>
<li>一个mr程序启动的时候，最先启动的是MRAppMaster，MRAppMaster启动后根据本次job的描述信息，计算出需要的maptask实例数量，然后向集群申请机器启动相应数量的maptask进程</li>
<li>maptask进程启动之后，根据给定的数据切片范围进行数据处理，主体流程为：<ol>
<li>利用客户指定的inputformat来获取RecordReader读取数据，形成输入KV对</li>
<li>将输入KV对传递给客户定义的map()方法，做逻辑运算，并将map()方法输出的KV对收集到缓存</li>
<li>将缓存中的KV对按照K分区排序后不断溢写到磁盘文件</li>
</ol>
</li>
<li>MRAppMaster监控到所有maptask进程任务完成之后，会根据客户指定的参数启动相应数量的reducetask进程，并告知reducetask进程要处理的数据范围（数据分区）</li>
<li>Reducetask进程启动之后，根据MRAppMaster告知的待处理数据所在位置，从若干台maptask运行所在机器上获取到若干个maptask输出结果文件，并在本地进行重新归并排序，然后按照相同key的KV为一个组，调用客户定义的reduce()方法进行逻辑运算，并收集运算输出的结果KV，然后调用客户指定的outputformat将结果数据输出到外部存储</li>
</ol>
<h2 id="16-简单描述一下HDFS的系统架构，怎么保证数据安全"><a href="#16-简单描述一下HDFS的系统架构，怎么保证数据安全" class="headerlink" title="16.简单描述一下HDFS的系统架构，怎么保证数据安全"></a>16.简单描述一下HDFS的系统架构，怎么保证数据安全</h2><p><img src="https://lixiangbetter.github.io/2020/07/02/Hadoop%E7%AC%94%E8%AE%B0/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTU3MzQ4Mi8yMDE5MDMvMTU3MzQ4Mi0yMDE5MDMwMTEzNTkzNzE1OS03ODYwNDI2MTgucG5n.jpeg" alt></p>
<p>HDFS数据安全性如何保证？</p>
<ol>
<li>存储在HDFS系统上的文件，会分割成128M大小的block存储在不同的节点上，block的副本数默认3份，也可配置成更多份；</li>
<li>第一个副本一般放置在与client（客户端）所在的同一节点上（若客户端无datanode，则随机放），第二个副本放置到与第一个副本同一机架的不同节点，第三个副本放到不同机架的datanode节点，当取用时遵循就近原则；</li>
<li>datanode以block为单位，每3s报告心跳状态，做10min内不报告心跳状态则namenode认为block已死掉，namonode会把其上面的数据备份到其他一个datanode节点上，保证数据的副本数量；</li>
<li>datanode会默认每小时把自己节点上的所有块状态信息报告给namenode；</li>
<li>采用safemode模式：datanode会周期性的报告block信息。Namenode会计算block的损坏率，当阀值&lt;0.999f时系统会进入安全模式，HDFS只读不写。 HDFS元数据采用secondaryname备份或者HA备份</li>
</ol>
<h2 id="17-在通过客户端向hdfs中写数据的时候，如果某一台机器宕机了，会怎么处理"><a href="#17-在通过客户端向hdfs中写数据的时候，如果某一台机器宕机了，会怎么处理" class="headerlink" title="17.在通过客户端向hdfs中写数据的时候，如果某一台机器宕机了，会怎么处理"></a>17.在通过客户端向hdfs中写数据的时候，如果某一台机器宕机了，会怎么处理</h2><p>在写入的时候不会重新分配datanode。 如果写入时，一个datanode挂掉，会将已经写入的数据放置到queue的顶部，并将挂掉的datanode移出pipline，将数据写入到剩余的datanode，在写入结束后， namenode会收集datanode的信息，发现此文件的replication没有达到配置的要求（default=3）,然后寻找一个datanode保存副本。</p>
<h2 id="18-Hadoop优化有哪些方面"><a href="#18-Hadoop优化有哪些方面" class="headerlink" title="18.Hadoop优化有哪些方面"></a>18.Hadoop优化有哪些方面</h2><p>0）HDFS 小文件影响</p>
<p>（1）影响 NameNode 的寿命，因为文件元数据存储在 NameNode 的内存中</p>
<p>（2）影响计算引擎的任务数量，比如每个小的文件都会生成一个 Map 任务</p>
<p>1）数据输入小文件处理：</p>
<p>（1）合并小文件：对小文件进行归档（Har）、自定义 Inputformat 将小文件存储成SequenceFile 文件。</p>
<p>（2）采用 ConbinFileInputFormat 来作为输入，解决输入端大量小文件场景。</p>
<p>（3）对于大量小文件 Job，可以开启 JVM 重用。</p>
<p>2）Map 阶段</p>
<p>（1）增大环形缓冲区大小。由 100m 扩大到 200m</p>
<p>（2）增大环形缓冲区溢写的比例。由 80%扩大到 90%</p>
<p>（3）减少对溢写文件的 merge 次数。（10 个文件，一次 20 个 merge）</p>
<p>（4）不影响实际业务的前提下，采用 Combiner 提前合并，减少 I/O。</p>
<p>3）Reduce 阶段</p>
<p>（1）合理设置 Map 和 Reduce 数：两个都不能设置太少，也不能设置太多。太少，会导致 Task 等待，延长处理时间；太多，会导致 Map、Reduce 任务间竞争资源，造成处理超时等错误。</p>
<p>（2）设置 Map、Reduce 共存：调整 slowstart.completedmaps 参数，使 Map 运行到一定程度后，Reduce 也开始运行，减少 Reduce 的等待时间。</p>
<p>（3）规避使用 Reduce，因为 Reduce 在用于连接数据集的时候将会产生大量的网络消耗。</p>
<p>（4）增加每个 Reduce 去 Map 中拿数据的并行数</p>
<p>（5）集群性能可以的前提下，增大 Reduce 端存储数据内存的大小。</p>
<p>4）IO 传输</p>
<p>（1）采用数据压缩的方式，减少网络 IO 的的时间。安装 Snappy 和 LZOP 压缩编码器。</p>
<p>（2）使用 SequenceFile 二进制文件</p>
<p>5）整体</p>
<p>（1）MapTask 默认内存大小为 1G，可以增加 MapTask 内存大小为 4-5g</p>
<p>（2）ReduceTask 默认内存大小为 1G，可以增加 ReduceTask 内存大小为 4-5g</p>
<p>（3）可以增加 MapTask 的 cpu 核数，增加 ReduceTask 的 CPU 核数</p>
<p>（4）增加每个 Container 的 CPU 核数和内存大小</p>
<p>（5）调整每个 Map Task 和 Reduce Task 最大重试次数</p>
<h2 id="19-大量数据求topN-写出mapreduce的实现思路）"><a href="#19-大量数据求topN-写出mapreduce的实现思路）" class="headerlink" title="19.大量数据求topN(写出mapreduce的实现思路）"></a>19.大量数据求topN(写出mapreduce的实现思路）</h2><p><a href="https://www.eyesmoons.com/article/31" target="_blank" rel="noopener">https://www.eyesmoons.com/article/31</a></p>
<p>​     在最初接触mapreduce时，top n问题的解决办法是将mapreduce输出（排序后）放入一个集合中，取前n个，但这种写法过于简单，内存能够加载的集合的大小是有上限的，一旦数据量大，很容易出现内存溢出。<br>​    如果要取top 5，则应该定义一个长度为6的数组，map所要做的事情就是将每条日志的那个需要排序的字段放入数组第一个元素中，调用Arrays.sort(Array[])方法可以将数组按照正序，从数字角度说是从小到大排序，比如第一条记录是9000，那么排序结果是[0,0,0,0,0,9000]，第二条日志记录是8000，排序结果是[0,0,0,0,8000,9000]，第三条日志记录是8500，排序结果是[0,0,0,8000,8500,9000]，以此类推，每次放进去一个数字如果大于数组里面最小的元素，相当于将最小的覆盖掉了，也就是说数组中元素永远是拿到日志中最大的那些个记录<br>​    ok，map将数组原封不动按照顺序输出，reduce接收到从每个map拿到的五个排好序的元素，在进行跟map一样的排序，排序后数组里面就是按照从小到大排好序的元素，将这些元素倒序输出就是最终我们要的结果了<br>​    与之前的方式做个比较，之前的map做的事情很少，在reduce中排序后拿前5条，reduce的压力是很大的，要把所有的数据都处理一遍，而一般设置reduce的个数较少，一旦数据较多，reduce就会承受不了，悲剧了。而现在的方式巧妙的将reduce的压力转移到了map，而map是集群效应的，很多台服务器来做这件事情，减少了一台机器上的负担，每个map其实只是输出了5个元素而已，如果有5个map，其实reduce才对5*5个数据进行了操作，也就不会出现内存溢出等问题了.</p>
<p>​    同样的思想，这个数据结构可以是，treemap,因为treemap的底层原理是红黑树，是有序的。</p>
<h2 id="20-列出正常工作的hadoop集群中hadoop都分别启动哪些进程以及他们的作用"><a href="#20-列出正常工作的hadoop集群中hadoop都分别启动哪些进程以及他们的作用" class="headerlink" title="20.列出正常工作的hadoop集群中hadoop都分别启动哪些进程以及他们的作用"></a>20.列出正常工作的hadoop集群中hadoop都分别启动哪些进程以及他们的作用</h2><p>1.NameNode它是hadoop中的主服务器，管理文件系统名称空间和对集群中存储的文件的访问，保存有metadate。</p>
<p>2.SecondaryNameNode它不是namenode的冗余守护进程，而是提供周期检查点和清理任务。帮助NN合并editslog，减少NN启动时间。</p>
<p>3.DataNode它负责管理连接到节点的存储（一个集群中可以有多个节点）。每个存储数据的节点运行一个datanode守护进程。</p>
<p>4.ResourceManager（JobTracker）JobTracker负责调度DataNode上的工作。每个DataNode有一个TaskTracker，它们执行实际工作。</p>
<p>5.NodeManager（TaskTracker）执行任务</p>
<p>6.DFSZKFailoverController高可用时它负责监控NN的状态，并及时的把状态信息写入ZK。它通过一个独立线程周期性的调用NN上的一个特定接口来获取NN的健康状态。FC也有选择谁作为Active NN的权利，因为最多只有两个节点，目前选择策略还比较简单（先到先得，轮换）。</p>
<p>7.JournalNode 高可用情况下存放namenode的editlog文件.</p>
<h2 id="21-Hadoop总job和Tasks之间的区别是什么？"><a href="#21-Hadoop总job和Tasks之间的区别是什么？" class="headerlink" title="21.Hadoop总job和Tasks之间的区别是什么？"></a>21.Hadoop总job和Tasks之间的区别是什么？</h2><p>Job是我们对一个完整的mapreduce程序的抽象封装</p>
<p>Task是job运行时，每一个处理阶段的具体实例，如map task，reduce task，maptask和reduce task都会有多个并发运行的实例</p>
<h2 id="22-Hadoop高可用HA模式"><a href="#22-Hadoop高可用HA模式" class="headerlink" title="22.Hadoop高可用HA模式"></a>22.Hadoop高可用HA模式</h2><p>HDFS高可用原理：</p>
<p>Hadoop HA（High Available）通过同时配置两个处于Active/Passive模式的Namenode来解决上述问题，状态分别是Active和Standby. Standby Namenode作为热备份，从而允许在机器发生故障时能够快速进行故障转移，同时在日常维护的时候使用优雅的方式进行Namenode切换。Namenode只能配置一主一备，不能多于两个Namenode。</p>
<p>主Namenode处理所有的操作请求（读写），而Standby只是作为slave，维护尽可能同步的状态，使得故障时能够快速切换到Standby。为了使Standby Namenode与Active Namenode数据保持同步，两个Namenode都与一组Journal Node进行通信。当主Namenode进行任务的namespace操作时，都会确保持久会修改日志到Journal Node节点中。Standby Namenode持续监控这些edit，当监测到变化时，将这些修改同步到自己的namespace。</p>
<p>当进行故障转移时，Standby在成为Active Namenode之前，会确保自己已经读取了Journal Node中的所有edit日志，从而保持数据状态与故障发生前一致。</p>
<p>为了确保故障转移能够快速完成，Standby Namenode需要维护最新的Block位置信息，即每个Block副本存放在集群中的哪些节点上。为了达到这一点，Datanode同时配置主备两个Namenode，并同时发送Block报告和心跳到两台Namenode。</p>
<p>确保任何时刻只有一个Namenode处于Active状态非常重要，否则可能出现数据丢失或者数据损坏。当两台Namenode都认为自己的Active Namenode时，会同时尝试写入数据（不会再去检测和同步数据）。为了防止这种脑裂现象，Journal Nodes只允许一个Namenode写入数据，内部通过维护epoch数来控制，从而安全地进行故障转移。</p>
<h2 id="23-简要描述安装配置一个hadoop集群的步骤"><a href="#23-简要描述安装配置一个hadoop集群的步骤" class="headerlink" title="23.简要描述安装配置一个hadoop集群的步骤"></a>23.简要描述安装配置一个hadoop集群的步骤</h2><ol>
<li>使用root账户登录。</li>
<li>修改IP。</li>
<li>修改Host主机名。</li>
<li>配置SSH免密码登录。</li>
<li>关闭防火墙。</li>
<li>安装JDK。</li>
<li>上传解压Hadoop安装包。</li>
<li>配置Hadoop的核心配置文件hadoop-evn.sh，core-site.xml，mapred-site.xml，hdfs-site.xml，yarn-site.xml</li>
<li>配置hadoop环境变量</li>
<li>格式化hdfs # bin/hadoop  namenode  -format</li>
<li>启动节点start-all.sh</li>
</ol>
<h2 id="24-fsimage和edit的区别"><a href="#24-fsimage和edit的区别" class="headerlink" title="24.fsimage和edit的区别"></a>24.fsimage和edit的区别</h2><p>fsimage：filesystem image 的简写，文件镜像。</p>
<p>客户端修改文件时候，先更新内存中的metadata信息,只有当对文件操作成功的时候，才会写到editlog。</p>
<p>fsimage是文件meta信息的持久化的检查点。secondary namenode会定期的将fsimage和editlog合并dump成新的fsimage</p>
<h2 id="25-yarn的三大调度策略"><a href="#25-yarn的三大调度策略" class="headerlink" title="25.yarn的三大调度策略"></a>25.yarn的三大调度策略</h2><p>FIFO Scheduler把应用按提交的顺序排成一个队列，这是一个先进先出队列，在进行资源分配的时候，先给队列中最头上的应用进行分配资源，待最头上的应用需求满足后再给下一个分配，以此类推。</p>
<p>Capacity（容量）调度器，有一个专门的队列用来运行小任务，但是为小任务专门设置一个队列会预先占用一定的集群资源，这就导致大任务的执行时间会落后于使用FIFO调度器时的时间。</p>
<p>在Fair（公平）调度器中，我们不需要预先占用一定的系统资源，Fair调度器会为所有运行的job动态的调整系统资源。当第一个大job提交时，只有这一个job在运行，此时它获得了所有集群资源；当第二个小任务提交后，Fair调度器会分配一半资源给这个小任务，让这两个任务公平的共享集群资源。</p>
<p>  需要注意的是，在下图Fair调度器中，从第二个任务提交到获得资源会有一定的延迟，因为它需要等待第一个任务释放占用的Container。小任务执行完成之后也会释放自己占用的资源，大任务又获得了全部的系统资源。最终的效果就是Fair调度器即得到了高的资源利用率又能保证小任务及时完成。</p>
<h2 id="26-hadoop的shell命令用的多吗-说出一些常用的"><a href="#26-hadoop的shell命令用的多吗-说出一些常用的" class="headerlink" title="26.hadoop的shell命令用的多吗?,说出一些常用的"></a>26.hadoop的shell命令用的多吗?,说出一些常用的</h2><p>hadoop  fs  -ls   /</p>
<p>hadoop fs  -mkdir  /aaa</p>
<p>hadoop fs -put /root/2.txt /haha/</p>
<p>hadoop fs -cat /haha/2.txt</p>
<p>hadoop fs -get /haha/2.txt </p>
<p>hadoop fs -rm -r -f /haha</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/hadoop/" rel="tag"># hadoop</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/07/01/MySQL数据库笔记/" rel="next" title="MySQL数据库笔记">
                <i class="fa fa-chevron-left"></i> MySQL数据库笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/07/05/hive笔记/" rel="prev" title="hive笔记">
                hive笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC80NjYwMC8yMzExMA=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="Lx">
            
              <p class="site-author-name" itemprop="name">Lx</p>
              <p class="site-description motion-element" itemprop="description">dreamer</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">23</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/lixiangbetter" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Hadoop笔记"><span class="nav-number">1.</span> <span class="nav-text">Hadoop笔记</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#一-Hadoop"><span class="nav-number">2.</span> <span class="nav-text">一.Hadoop</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-hdfs写流程"><span class="nav-number">2.1.</span> <span class="nav-text">1.hdfs写流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-hdfs读流程"><span class="nav-number">2.2.</span> <span class="nav-text">2.hdfs读流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-hdfs的体系结构"><span class="nav-number">2.3.</span> <span class="nav-text">3.hdfs的体系结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-一个datanode-宕机-怎么一个流程恢复"><span class="nav-number">2.4.</span> <span class="nav-text">4.一个datanode 宕机,怎么一个流程恢复</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-hadoop-的-namenode-宕机-怎么解决"><span class="nav-number">2.5.</span> <span class="nav-text">5.hadoop 的 namenode 宕机,怎么解决</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-namenode对元数据的管理"><span class="nav-number">2.6.</span> <span class="nav-text">6.namenode对元数据的管理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-元数据的checkpoint"><span class="nav-number">2.7.</span> <span class="nav-text">7.元数据的checkpoint</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-yarn资源调度流程"><span class="nav-number">2.8.</span> <span class="nav-text">8.yarn资源调度流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-hadoop中combiner和partition的作用"><span class="nav-number">2.9.</span> <span class="nav-text">9.hadoop中combiner和partition的作用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-用mapreduce怎么处理数据倾斜问题？"><span class="nav-number">2.10.</span> <span class="nav-text">10.用mapreduce怎么处理数据倾斜问题？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-shuffle-阶段-你怎么理解的"><span class="nav-number">2.11.</span> <span class="nav-text">11.shuffle 阶段,你怎么理解的</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13-MapReduce优化经验"><span class="nav-number">2.12.</span> <span class="nav-text">13.MapReduce优化经验</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#14-分别举例什么情况要使用-combiner，什么情况不使用？"><span class="nav-number">2.13.</span> <span class="nav-text">14.分别举例什么情况要使用 combiner，什么情况不使用？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#15-MR运行流程解析"><span class="nav-number">2.14.</span> <span class="nav-text">15.MR运行流程解析</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#16-简单描述一下HDFS的系统架构，怎么保证数据安全"><span class="nav-number">2.15.</span> <span class="nav-text">16.简单描述一下HDFS的系统架构，怎么保证数据安全</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#17-在通过客户端向hdfs中写数据的时候，如果某一台机器宕机了，会怎么处理"><span class="nav-number">2.16.</span> <span class="nav-text">17.在通过客户端向hdfs中写数据的时候，如果某一台机器宕机了，会怎么处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#18-Hadoop优化有哪些方面"><span class="nav-number">2.17.</span> <span class="nav-text">18.Hadoop优化有哪些方面</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#19-大量数据求topN-写出mapreduce的实现思路）"><span class="nav-number">2.18.</span> <span class="nav-text">19.大量数据求topN(写出mapreduce的实现思路）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#20-列出正常工作的hadoop集群中hadoop都分别启动哪些进程以及他们的作用"><span class="nav-number">2.19.</span> <span class="nav-text">20.列出正常工作的hadoop集群中hadoop都分别启动哪些进程以及他们的作用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#21-Hadoop总job和Tasks之间的区别是什么？"><span class="nav-number">2.20.</span> <span class="nav-text">21.Hadoop总job和Tasks之间的区别是什么？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#22-Hadoop高可用HA模式"><span class="nav-number">2.21.</span> <span class="nav-text">22.Hadoop高可用HA模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#23-简要描述安装配置一个hadoop集群的步骤"><span class="nav-number">2.22.</span> <span class="nav-text">23.简要描述安装配置一个hadoop集群的步骤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#24-fsimage和edit的区别"><span class="nav-number">2.23.</span> <span class="nav-text">24.fsimage和edit的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#25-yarn的三大调度策略"><span class="nav-number">2.24.</span> <span class="nav-text">25.yarn的三大调度策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#26-hadoop的shell命令用的多吗-说出一些常用的"><span class="nav-number">2.25.</span> <span class="nav-text">26.hadoop的shell命令用的多吗?,说出一些常用的</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lx</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <!--<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>-->
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>
